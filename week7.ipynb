{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for reading in data and anaylzing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    data = pd.read_csv(file)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SubjectID  VideoID  Attention  Mediation    Raw      Delta     Theta  \\\n",
      "0        0.0      0.0       56.0       43.0  278.0   301963.0   90612.0   \n",
      "1        0.0      0.0       40.0       35.0  -50.0    73787.0   28083.0   \n",
      "2        0.0      0.0       47.0       48.0  101.0   758353.0  383745.0   \n",
      "3        0.0      0.0       47.0       57.0   -5.0  2012240.0  129350.0   \n",
      "4        0.0      0.0       44.0       53.0   -8.0  1005145.0  354328.0   \n",
      "\n",
      "     Alpha1   Alpha2    Beta1     Beta2   Gamma1   Gamma2  predefinedlabel  \\\n",
      "0   33735.0  23991.0  27946.0   45097.0  33228.0   8293.0              0.0   \n",
      "1    1439.0   2240.0   2746.0    3687.0   5293.0   2740.0              0.0   \n",
      "2  201999.0  62107.0  36293.0  130536.0  57243.0  25354.0              0.0   \n",
      "3   61236.0  17084.0  11488.0   62462.0  49960.0  33932.0              0.0   \n",
      "4   37102.0  88881.0  45307.0   99603.0  44790.0  29749.0              0.0   \n",
      "\n",
      "   user-definedlabeln  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 0.0  \n",
      "num of samples 12811\n",
      "num of features 14\n",
      "Logistic Regression Accuracy: 0.6009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml_env/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "df = read_data('EEG Data 2025SP CMP SC 4540 01.csv')\n",
    "print(df.head())\n",
    "print(\"num of samples\", df.shape[0])\n",
    "print(\"num of features\", df.shape[1]-1)\n",
    "\n",
    "X = df.iloc[:, :14].values\n",
    "y = df.iloc[:, 14].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_log:.4f}\")\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).reshape(-1, 1).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The features which are inputs are the columns 0->14 and the last one is the target or label. This is a classification problem since the lables are labled 0 or 1 showing binary classification depending on the features. As a result this is used to find a line with the features and lables using a loss function to determine the line that best fit for predicting whether it is 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(14, 8)\n",
    "        self.layer2 = nn.Linear(8, 1)  \n",
    "        self.sigmoid = nn.Sigmoid()    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = self.sigmoid(self.layer2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000, Loss: 39.2005\n",
      "Epoch 40/1000, Loss: 34.1476\n",
      "Epoch 60/1000, Loss: 32.1316\n",
      "Epoch 80/1000, Loss: 26.4031\n",
      "Epoch 100/1000, Loss: 18.0124\n",
      "Epoch 120/1000, Loss: 8.4271\n",
      "Epoch 140/1000, Loss: 1.7500\n",
      "Epoch 160/1000, Loss: 0.7017\n",
      "Epoch 180/1000, Loss: 0.6921\n",
      "Epoch 200/1000, Loss: 0.6921\n",
      "Epoch 220/1000, Loss: 0.6921\n",
      "Epoch 240/1000, Loss: 0.6921\n",
      "Epoch 260/1000, Loss: 0.6921\n",
      "Epoch 280/1000, Loss: 0.6921\n",
      "Epoch 300/1000, Loss: 0.6921\n",
      "Epoch 320/1000, Loss: 0.6921\n",
      "Epoch 340/1000, Loss: 0.6921\n",
      "Epoch 360/1000, Loss: 0.6921\n",
      "Epoch 380/1000, Loss: 0.6921\n",
      "Epoch 400/1000, Loss: 0.6921\n",
      "Epoch 420/1000, Loss: 0.6921\n",
      "Epoch 440/1000, Loss: 0.6921\n",
      "Epoch 460/1000, Loss: 0.6921\n",
      "Epoch 480/1000, Loss: 0.6921\n",
      "Epoch 500/1000, Loss: 0.6921\n",
      "Epoch 520/1000, Loss: 0.6921\n",
      "Epoch 540/1000, Loss: 0.6921\n",
      "Epoch 560/1000, Loss: 0.6921\n",
      "Epoch 580/1000, Loss: 0.6921\n",
      "Epoch 600/1000, Loss: 0.6921\n",
      "Epoch 620/1000, Loss: 0.6921\n",
      "Epoch 640/1000, Loss: 0.6921\n",
      "Epoch 660/1000, Loss: 0.6921\n",
      "Epoch 680/1000, Loss: 0.6921\n",
      "Epoch 700/1000, Loss: 0.6921\n",
      "Epoch 720/1000, Loss: 0.6921\n",
      "Epoch 740/1000, Loss: 0.6921\n",
      "Epoch 760/1000, Loss: 0.6921\n",
      "Epoch 780/1000, Loss: 0.6921\n",
      "Epoch 800/1000, Loss: 0.6921\n",
      "Epoch 820/1000, Loss: 0.6921\n",
      "Epoch 840/1000, Loss: 0.6921\n",
      "Epoch 860/1000, Loss: 0.6921\n",
      "Epoch 880/1000, Loss: 0.6921\n",
      "Epoch 900/1000, Loss: 0.6921\n",
      "Epoch 920/1000, Loss: 0.6921\n",
      "Epoch 940/1000, Loss: 0.6921\n",
      "Epoch 960/1000, Loss: 0.6921\n",
      "Epoch 980/1000, Loss: 0.6921\n",
      "Epoch 1000/1000, Loss: 0.6921\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_nn = model(X_test_tensor)\n",
    "    y_pred_nn = (y_pred_nn > 0.5).float().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.4943\n"
     ]
    }
   ],
   "source": [
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"Neural Network Accuracy: {accuracy_nn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison:\n",
      "Logistic Regression: 0.6009\n",
      "Neural Network: 0.4943\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"Logistic Regression: {accuracy_log:.4f}\")\n",
    "print(f\"Neural Network: {accuracy_nn:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
